{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66760fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2618e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA compute ok\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1024, 1024, device=\"cuda\")\n",
    "y = x @ x\n",
    "torch.cuda.synchronize()\n",
    "print(\"CUDA compute ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701341ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import rasterio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "\n",
    "IMG_SIZE = 384\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "PAD_WIDTH = 6\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e439cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  category_id\n",
       "0        1            0\n",
       "1        2           -1\n",
       "2        3            0\n",
       "3        4            0\n",
       "4        5            0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = r\"C:\\SP2026DS\\dsc-competition-2026-sdl-satellite-detection\"\n",
    "\n",
    "train_dir = os.path.join(DATA, \"train_images/train_images\")\n",
    "test_dir  = os.path.join(DATA, \"test_images/test_images\")\n",
    "label_csv = os.path.join(DATA, \"train_labels.csv\")\n",
    "\n",
    "labels_df = pd.read_csv(label_csv)\n",
    "labels_df[\"image_id\"] = labels_df[\"image_id\"].astype(str)\n",
    "labels_df[\"category_id\"] = labels_df[\"category_id\"].astype(int)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6be50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " category_id  label_id\n",
      "          -1         0\n",
      "           0         1\n",
      "           1         2\n",
      "           2         3\n",
      "           3         4\n",
      "           4         5\n",
      "           5         6\n"
     ]
    }
   ],
   "source": [
    "unique_sat_ids = sorted(labels_df[\"category_id\"].unique())\n",
    "id_to_idx = {sid: i for i, sid in enumerate(unique_sat_ids)}\n",
    "idx_to_id = {i: sid for sid, i in id_to_idx.items()}\n",
    "\n",
    "labels_df[\"label_id\"] = labels_df[\"category_id\"].map(id_to_idx).astype(int)\n",
    "mapping_df = labels_df[[\"category_id\", \"label_id\"]].drop_duplicates().sort_values(\"label_id\")\n",
    "print(mapping_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b697b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tif_as_hwc_float01(path: str) -> np.ndarray:\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read()\n",
    "\n",
    "    if arr.ndim == 2:\n",
    "        arr = arr[:, :, None]\n",
    "    elif arr.ndim == 3:\n",
    "        arr = np.transpose(arr, (1, 2, 0))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected tif array shape: {arr.shape}\")\n",
    "\n",
    "    arr = arr.astype(np.float32)\n",
    "\n",
    "    if arr.shape[2] >= 3:\n",
    "        arr = arr[:, :, :3]\n",
    "    else:\n",
    "        arr = np.repeat(arr, 3, axis=2)\n",
    "\n",
    "    mn = float(np.nanmin(arr))\n",
    "    mx = float(np.nanmax(arr))\n",
    "    arr = (arr - mn) / (mx - mn + 1e-6)\n",
    "    arr = np.nan_to_num(arr, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62533e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, pad_width=PAD_WIDTH):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.pad_width = pad_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row[\"image_id\"]).zfill(self.pad_width)\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.tif\")\n",
    "\n",
    "        img = read_tif_as_hwc_float01(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = int(row[\"label_id\"])\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc78fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ddc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    labels_df,\n",
    "    test_size=0.2,\n",
    "    random_state=123,\n",
    "    stratify=labels_df[\"label_id\"],\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop=True)\n",
    "\n",
    "train_ds = SatelliteDataset(train_df, train_dir, transform=train_transform, pad_width=PAD_WIDTH)\n",
    "val_ds   = SatelliteDataset(val_df, train_dir, transform=val_transform, pad_width=PAD_WIDTH)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75f0915",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.ConvNeXt_Tiny_Weights.DEFAULT\n",
    "\n",
    "try:\n",
    "    model = models.convnext_tiny(weights=weights)\n",
    "except Exception as e:\n",
    "    print(\"Pretrained weights failed to load, weights=None.\")\n",
    "    print(\"Error:\", e)\n",
    "    model = models.convnext_tiny(weights=None)\n",
    "\n",
    "model.classifier[2] = nn.Linear(model.classifier[2].in_features, NUM_CLASSES)\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d366ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train_df[\"label_id\"].value_counts()\n",
    "\n",
    "weights = torch.zeros(NUM_CLASSES, dtype=torch.float32)\n",
    "for i in range(NUM_CLASSES):\n",
    "    weights[i] = 1.0 / counts.get(i, 1)\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(DEVICE))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c4be58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31454 3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch sec: 0.3289318084716797\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(train_loader))\n",
    "import time\n",
    "t0=time.time(); _=next(iter(train_loader)); print(\"first batch sec:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a860a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_cuda)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMP enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/3932 [00:00<?, ?it/s]C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 1/30: 100%|██████████| 3932/3932 [23:39<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | lr: 0.000100 | Loss: 1.0377 | Train Acc: 0.5800 | Val Acc: 0.6989 | Val F1(w): 0.6966 | Val F1(m): 0.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 2/30: 100%|██████████| 3932/3932 [23:33<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | lr: 0.000100 | Loss: 0.7743 | Train Acc: 0.6915 | Val Acc: 0.7379 | Val F1(w): 0.7368 | Val F1(m): 0.7558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 3/30: 100%|██████████| 3932/3932 [22:24<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | lr: 0.000099 | Loss: 0.7168 | Train Acc: 0.7174 | Val Acc: 0.7546 | Val F1(w): 0.7508 | Val F1(m): 0.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 4/30: 100%|██████████| 3932/3932 [22:15<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | lr: 0.000098 | Loss: 0.6700 | Train Acc: 0.7358 | Val Acc: 0.7842 | Val F1(w): 0.7849 | Val F1(m): 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 5/30: 100%|██████████| 3932/3932 [22:09<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | lr: 0.000096 | Loss: 0.6395 | Train Acc: 0.7476 | Val Acc: 0.7916 | Val F1(w): 0.7904 | Val F1(m): 0.8031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 6/30: 100%|██████████| 3932/3932 [22:17<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | lr: 0.000093 | Loss: 0.6147 | Train Acc: 0.7543 | Val Acc: 0.7887 | Val F1(w): 0.7876 | Val F1(m): 0.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 7/30: 100%|██████████| 3932/3932 [22:31<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | lr: 0.000090 | Loss: 0.5944 | Train Acc: 0.7635 | Val Acc: 0.8128 | Val F1(w): 0.8127 | Val F1(m): 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 8/30: 100%|██████████| 3932/3932 [21:45<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | lr: 0.000087 | Loss: 0.5704 | Train Acc: 0.7750 | Val Acc: 0.8206 | Val F1(w): 0.8195 | Val F1(m): 0.8293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 9/30: 100%|██████████| 3932/3932 [21:44<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | lr: 0.000083 | Loss: 0.5534 | Train Acc: 0.7795 | Val Acc: 0.8049 | Val F1(w): 0.8057 | Val F1(m): 0.8132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 10/30: 100%|██████████| 3932/3932 [21:35<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | lr: 0.000079 | Loss: 0.5383 | Train Acc: 0.7869 | Val Acc: 0.8188 | Val F1(w): 0.8195 | Val F1(m): 0.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 11/30: 100%|██████████| 3932/3932 [21:34<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | lr: 0.000075 | Loss: 0.5192 | Train Acc: 0.7927 | Val Acc: 0.8369 | Val F1(w): 0.8369 | Val F1(m): 0.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 12/30: 100%|██████████| 3932/3932 [21:21<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | lr: 0.000070 | Loss: 0.5018 | Train Acc: 0.7999 | Val Acc: 0.8426 | Val F1(w): 0.8428 | Val F1(m): 0.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 13/30: 100%|██████████| 3932/3932 [21:19<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | lr: 0.000065 | Loss: 0.4832 | Train Acc: 0.8050 | Val Acc: 0.8455 | Val F1(w): 0.8467 | Val F1(m): 0.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 14/30: 100%|██████████| 3932/3932 [22:28<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | lr: 0.000060 | Loss: 0.4671 | Train Acc: 0.8141 | Val Acc: 0.8505 | Val F1(w): 0.8508 | Val F1(m): 0.8577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 15/30: 100%|██████████| 3932/3932 [22:07<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | lr: 0.000055 | Loss: 0.4525 | Train Acc: 0.8181 | Val Acc: 0.8554 | Val F1(w): 0.8561 | Val F1(m): 0.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 16/30: 100%|██████████| 3932/3932 [21:59<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | lr: 0.000050 | Loss: 0.4375 | Train Acc: 0.8270 | Val Acc: 0.8569 | Val F1(w): 0.8560 | Val F1(m): 0.8632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 17/30: 100%|██████████| 3932/3932 [21:53<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | lr: 0.000045 | Loss: 0.4226 | Train Acc: 0.8323 | Val Acc: 0.8581 | Val F1(w): 0.8576 | Val F1(m): 0.8637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30:   0%|          | 0/3932 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\3779051656.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_cuda):\n",
      "Epoch 18/30:   2%|▏         | 90/3932 [00:27<19:37,  3.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m running_correct = \u001b[32m0\u001b[39m\n\u001b[32m     15\u001b[39m running_total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mSatelliteDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     16\u001b[39m img = read_tif_as_hwc_float01(img_path)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m label = \u001b[38;5;28mint\u001b[39m(row[\u001b[33m\"\u001b[39m\u001b[33mlabel_id\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1372\u001b[39m, in \u001b[36mRandomRotation.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m   1369\u001b[39m         fill = [\u001b[38;5;28mfloat\u001b[39m(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fill]\n\u001b[32m   1370\u001b[39m angle = \u001b[38;5;28mself\u001b[39m.get_params(\u001b[38;5;28mself\u001b[39m.degrees)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1121\u001b[39m, in \u001b[36mrotate\u001b[39m\u001b[34m(img, angle, interpolation, expand, center, fill)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.Tensor):\n\u001b[32m   1120\u001b[39m     pil_interpolation = pil_modes_mapping[interpolation]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m center_f = [\u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m]\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:314\u001b[39m, in \u001b[36mrotate\u001b[39m\u001b[34m(img, angle, interpolation, expand, center, fill)\u001b[39m\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimg should be PIL Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    313\u001b[39m opts = _parse_fill(fill, img)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\PIL\\Image.py:2453\u001b[39m, in \u001b[36mImage.rotate\u001b[39m\u001b[34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[39m\n\u001b[32m   2450\u001b[39m     matrix[\u001b[32m2\u001b[39m], matrix[\u001b[32m5\u001b[39m] = transform(-(nw - w) / \u001b[32m2.0\u001b[39m, -(nh - h) / \u001b[32m2.0\u001b[39m, matrix)\n\u001b[32m   2451\u001b[39m     w, h = nw, nh\n\u001b[32m-> \u001b[39m\u001b[32m2453\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2454\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAFFINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfillcolor\u001b[49m\n\u001b[32m   2455\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\PIL\\Image.py:2865\u001b[39m, in \u001b[36mImage.transform\u001b[39m\u001b[34m(self, size, method, data, resample, fill, fillcolor)\u001b[39m\n\u001b[32m   2861\u001b[39m         im.__transformer(\n\u001b[32m   2862\u001b[39m             box, \u001b[38;5;28mself\u001b[39m, Transform.QUAD, quad, resample, fillcolor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2863\u001b[39m         )\n\u001b[32m   2864\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2865\u001b[39m     \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2866\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillcolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m im\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SP2026DS\\torchgpu\\Lib\\site-packages\\PIL\\Image.py:2955\u001b[39m, in \u001b[36mImage.__transformer\u001b[39m\u001b[34m(self, box, image, method, data, resample, fill)\u001b[39m\n\u001b[32m   2952\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image.mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2953\u001b[39m     resample = Resampling.NEAREST\n\u001b[32m-> \u001b[39m\u001b[32m2955\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "use_cuda = (DEVICE.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_cuda)\n",
    "print(\"AMP enabled:\", scaler.is_enabled())\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "best_f1 = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=use_cuda):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if i == 0:\n",
    "            print(\"first batch done, loss =\", float(loss))\n",
    "            \n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        running_total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / running_total\n",
    "    train_acc = running_correct / running_total\n",
    "\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_y_true = []\n",
    "    val_y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            # collect for F1\n",
    "            val_y_true.extend(labels.detach().cpu().numpy().tolist())\n",
    "            val_y_pred.extend(preds.detach().cpu().numpy().tolist())\n",
    "\n",
    "    val_acc = val_correct / max(val_total, 1)\n",
    "\n",
    "    val_f1_weighted = f1_score(val_y_true, val_y_pred, average=\"weighted\")\n",
    "    val_f1_macro = f1_score(val_y_true, val_y_pred, average=\"macro\")\n",
    "\n",
    "    if val_f1_weighted > best_f1:\n",
    "        best_f1 = val_f1_weighted\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} | lr: {current_lr:.6f} | \"\n",
    "        f\"Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "        f\"Val Acc: {val_acc:.4f} | Val F1(w): {val_f1_weighted:.4f} | Val F1(m): {val_f1_macro:.4f}\"\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "# restore best weights at end\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(DEVICE)\n",
    "    print(f\"Best model by weighted F1 = {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bad1ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved convnext_tiny_best.pth | best_f1 = 0.8576002263508908\n"
     ]
    }
   ],
   "source": [
    "torch.save(best_state, \"convnext_tiny_best.pth\")\n",
    "print(\"Saved convnext_tiny_best.pth | best_f1 =\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f527d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\1436124646.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"convnext_tiny_best.pth\", map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.load(\"convnext_tiny_best.pth\", map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cba7fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting (batched + hflip TTA): 100%|██████████| 308/308 [07:34<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submissionFinal.csv with 9834 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>satellite_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  satellite_id\n",
       "0   000001             0\n",
       "1   000002             0\n",
       "2   000003             4\n",
       "3   000004             4\n",
       "4   000005             5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "test_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(\".tif\")])\n",
    "\n",
    "BATCH = 32 \n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in tqdm(range(0, len(test_files), BATCH), desc=\"Predicting (batched + hflip TTA)\"):\n",
    "        batch_files = test_files[start:start+BATCH]\n",
    "\n",
    "        xs = []\n",
    "        img_ids = []\n",
    "        for fname in batch_files:\n",
    "            img_ids.append(os.path.splitext(fname)[0])\n",
    "            img_path = os.path.join(test_dir, fname)\n",
    "\n",
    "            img = read_tif_as_hwc_float01(img_path)   \n",
    "            xs.append(val_transform(img))             \n",
    "\n",
    "        x = torch.stack(xs, dim=0).to(DEVICE, non_blocking=True)\n",
    "\n",
    "\n",
    "        probs1 = F.softmax(model(x), dim=1)\n",
    "        probs2 = F.softmax(model(torch.flip(x, dims=[3])), dim=1)\n",
    "        probs = 0.5 * (probs1 + probs2)\n",
    "\n",
    "        pred_idxs = probs.argmax(dim=1).detach().cpu().numpy().tolist()\n",
    "\n",
    "        for img_id, pred_idx in zip(img_ids, pred_idxs):\n",
    "            results.append((img_id, idx_to_id[pred_idx]))\n",
    "\n",
    "submission = pd.DataFrame(results, columns=[\"image_id\", \"satellite_id\"])\n",
    "submission.to_csv(\"submissionFinal.csv\", index=False)\n",
    "\n",
    "print(\"submissionFinal.csv with\", len(submission), \"rows\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fed13daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itsam\\AppData\\Local\\Temp\\ipykernel_14868\\1151003748.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  obj = torch.load(path, map_location=device)\n",
      "Predicting ensemble:   0%|          | 0/308 [00:00<?, ?it/s]c:\\SP2026DS\\torchgpu\\Lib\\site-packages\\rasterio\\__init__.py:368: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n",
      "  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n",
      "Predicting ensemble: 100%|██████████| 308/308 [04:45<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submissionFinalEnsemble.csv | rows: 9834 | alpha: 0.8 | TTA: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>satellite_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  satellite_id\n",
       "0   000001             0\n",
       "1   000002             0\n",
       "2   000003             4\n",
       "3   000004             4\n",
       "4   000005             5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ALPHA = 0.80        \n",
    "USE_TTA = False    \n",
    "BATCH = 32          \n",
    "\n",
    "def build_convnext_tiny(num_classes):\n",
    "    m = models.convnext_tiny(weights=None)\n",
    "    m.classifier[2] = nn.Linear(m.classifier[2].in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def build_resnet18(num_classes):\n",
    "    m = models.resnet18(weights=None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def load_weights_flexible(model, path, device):\n",
    "    obj = torch.load(path, map_location=device)\n",
    "    if isinstance(obj, dict) and \"model_state\" in obj:\n",
    "        model.load_state_dict(obj[\"model_state\"])\n",
    "        return obj\n",
    "    else:\n",
    "        model.load_state_dict(obj)\n",
    "        return None\n",
    "\n",
    "convnext = build_convnext_tiny(NUM_CLASSES).to(DEVICE).eval()\n",
    "resnet   = build_resnet18(NUM_CLASSES).to(DEVICE).eval()\n",
    "\n",
    "_ = load_weights_flexible(convnext, \"convnext_tiny_best.pth\", DEVICE)\n",
    "_ = load_weights_flexible(resnet,   \"resnet18_best.pth\", DEVICE)\n",
    "\n",
    "@torch.no_grad()\n",
    "def probs_model(model, x, use_tta=False):\n",
    "    p = F.softmax(model(x), dim=1)\n",
    "    if use_tta:\n",
    "        p2 = F.softmax(model(torch.flip(x, dims=[3])), dim=1)\n",
    "        p = 0.5 * (p + p2)\n",
    "    return p\n",
    "\n",
    "# Predict\n",
    "test_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith(\".tif\")])\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for start in tqdm(range(0, len(test_files), BATCH), desc=\"Predicting ensemble\"):\n",
    "        batch_files = test_files[start:start+BATCH]\n",
    "\n",
    "        xs, img_ids = [], []\n",
    "        for fname in batch_files:\n",
    "            img_ids.append(os.path.splitext(fname)[0])\n",
    "            img = read_tif_as_hwc_float01(os.path.join(test_dir, fname))\n",
    "            xs.append(val_transform(img))\n",
    "\n",
    "        x = torch.stack(xs, dim=0).to(DEVICE, non_blocking=True)\n",
    "\n",
    "        p_c = probs_model(convnext, x, use_tta=USE_TTA)\n",
    "        p_r = probs_model(resnet,   x, use_tta=USE_TTA)\n",
    "\n",
    "        p = ALPHA * p_c + (1 - ALPHA) * p_r\n",
    "        pred_idxs = p.argmax(dim=1).detach().cpu().tolist()\n",
    "\n",
    "        for img_id, pred_idx in zip(img_ids, pred_idxs):\n",
    "            results.append((img_id, idx_to_id[pred_idx]))\n",
    "\n",
    "submission = pd.DataFrame(results, columns=[\"image_id\", \"satellite_id\"])\n",
    "submission.to_csv(\"submissionFinalEnsemble.csv\", index=False)\n",
    "\n",
    "print(\"Wrote submissionFinalEnsemble.csv | rows:\", len(submission), \"| alpha:\", ALPHA, \"| TTA:\", USE_TTA)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
